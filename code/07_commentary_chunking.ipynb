{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pytesseract\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# IMPORTANT: Update this path if Tesseract is not in your system's PATH\n",
    "# Example for Windows: pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "# Example for Linux/macOS (if installed in a non-standard location): pytesseract.pytesseract.tesseract_cmd = '/usr/local/bin/tesseract'\n",
    "# If Tesseract is in your PATH, you might be able to comment this line out.\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'<full_path_to_your_tesseract_executable>'\n",
    "\n",
    "# --- IMPORTANT: SET THESE PATHS ---\n",
    "PDF_FILE_PATH = '01.pdf'  # The path to your input PDF file\n",
    "OUTPUT_JSON_PATH = 'schlafly_commentaries_jan_2002.json' # The path for the output JSON file\n",
    "# Path to Poppler binaries (required by pdf2image) - uncomment and set if not in PATH\n",
    "# POPPLER_PATH = r\"C:\\path\\to\\poppler-xx.xx.x\\bin\" # Example for Windows\n",
    "POPPLER_PATH = None # Set this if needed, otherwise keep as None\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def is_weekday(d):\n",
    "    \"\"\"Checks if a given date is a weekday (Monday to Friday).\"\"\"\n",
    "    return d.weekday() < 5\n",
    "\n",
    "def get_next_weekday(d):\n",
    "    \"\"\"Gets the next weekday after the given date.\"\"\"\n",
    "    next_day = d + timedelta(days=1)\n",
    "    while not is_weekday(next_day):\n",
    "        next_day += timedelta(days=1)\n",
    "    return next_day\n",
    "\n",
    "def calculate_date_from_number(commentary_num_str):\n",
    "    \"\"\"\n",
    "    Calculates the date based on the commentary number (e.g., '02-01').\n",
    "    Assumes 02-01 is Jan 2, 2002, and subsequent numbers are sequential weekdays.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = commentary_num_str.split('-')\n",
    "        if len(parts) != 2 or not parts[0] == '02': # Expecting format '02-XX' for Jan 2002\n",
    "             return \"Unknown Date\"\n",
    "\n",
    "        day_index = int(parts[1]) - 1 # 0-based index for calculation\n",
    "        if day_index < 0:\n",
    "            return \"Unknown Date\"\n",
    "\n",
    "        # Start date is Wednesday, January 2, 2002 (based on PDF first page)\n",
    "        current_date = date(2002, 1, 2)\n",
    "        days_added = 0\n",
    "\n",
    "        # Find the correct weekday date corresponding to the index\n",
    "        while days_added < day_index:\n",
    "            current_date = get_next_weekday(current_date)\n",
    "            days_added += 1\n",
    "\n",
    "        return current_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    except (ValueError, IndexError):\n",
    "        print(f\"Warning: Could not parse date for commentary number {commentary_num_str}\")\n",
    "        return \"Unknown Date\"\n",
    "\n",
    "\n",
    "def extract_text_from_pdf_ocr(pdf_path, poppler_path=None):\n",
    "    \"\"\"\n",
    "    Extracts text from a non-OCR PDF using OCR (Tesseract via pdf2image).\n",
    "    Returns a list of strings, where each string is the text of a page.\n",
    "    \"\"\"\n",
    "    print(f\"Starting OCR process for {pdf_path}...\")\n",
    "    all_page_text = []\n",
    "    try:\n",
    "        # Convert PDF pages to images\n",
    "        # Use dpi=300 for better OCR quality, adjust if needed\n",
    "        images = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)\n",
    "        print(f\"Converted {len(images)} pages to images.\")\n",
    "\n",
    "        # Perform OCR on each image\n",
    "        for i, img in enumerate(images):\n",
    "            print(f\"Performing OCR on page {i + 1}/{len(images)}...\")\n",
    "            try:\n",
    "                # Use pytesseract to extract text\n",
    "                # lang='eng' specifies English language\n",
    "                page_text = pytesseract.image_to_string(img, lang='eng')\n",
    "                all_page_text.append(page_text)\n",
    "                print(f\"Page {i + 1} OCR complete.\")\n",
    "            except pytesseract.TesseractNotFoundError:\n",
    "                print(\"\\n--- TESSERACT NOT FOUND ---\")\n",
    "                print(\"Error: Tesseract is not installed or not in your PATH.\")\n",
    "                print(\"Please install Tesseract OCR and configure the path in the script if necessary.\")\n",
    "                print(\"Installation guide: https://github.com/tesseract-ocr/tesseract#installing-tesseract\")\n",
    "                return None\n",
    "            except Exception as ocr_err:\n",
    "                print(f\"Error during OCR on page {i + 1}: {ocr_err}\")\n",
    "                all_page_text.append(\"\") # Add empty string on error\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF or converting pages: {e}\")\n",
    "        if \"poppler\" in str(e).lower():\n",
    "             print(\"\\n--- POPPLER ERROR ---\")\n",
    "             print(\"This might be due to Poppler not being installed or not found.\")\n",
    "             print(\"Please install Poppler and provide the path in the POPPLER_PATH variable if needed.\")\n",
    "        return None\n",
    "\n",
    "    print(\"OCR process finished.\")\n",
    "    return all_page_text\n",
    "\n",
    "def parse_commentaries(all_pages_text):\n",
    "    \"\"\"\n",
    "    Parses the extracted text to find and structure commentaries.\n",
    "    \"\"\"\n",
    "    print(\"Parsing extracted text for commentaries...\")\n",
    "    commentaries = []\n",
    "    full_text = \"\\n\".join(all_pages_text) # Combine all pages for easier parsing\n",
    "\n",
    "    # Regex to find commentary headers:\n",
    "    # - Optional leading whitespace/newlines\n",
    "    # - Commentary Number (e.g., 02-01) on its own line (potentially with whitespace)\n",
    "    # - Title on the next line (captures everything until the next newline)\n",
    "    # - Category might be above the title or number, but the most reliable marker seems to be the number.\n",
    "    # Let's try finding the number first, then look for title nearby.\n",
    "    # This regex looks for the number, then captures the text *before* it (potential title/category)\n",
    "    # and the text *after* it until the next commentary number or end of text.\n",
    "\n",
    "    # Revised Regex Strategy: Find number, then work backwards/forwards\n",
    "    # Pattern to find the commentary number marker (e.g., 02-01) potentially surrounded by whitespace/newlines\n",
    "    # We capture the number itself.\n",
    "    pattern = re.compile(r\"^\\s*(\\d{2}-\\d{2})\\s*$\", re.MULTILINE)\n",
    "\n",
    "    matches = list(pattern.finditer(full_text))\n",
    "    print(f\"Found {len(matches)} potential commentary number markers.\")\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        commentary_data = {}\n",
    "        commentary_num = match.group(1)\n",
    "        start_index = match.end() # Start of commentary text is after the number marker\n",
    "\n",
    "        # End index is the start of the *next* commentary number marker, or end of text\n",
    "        end_index = matches[i + 1].start() if (i + 1) < len(matches) else len(full_text)\n",
    "\n",
    "        # Extract the raw text block associated with this number\n",
    "        raw_block = full_text[start_index:end_index]\n",
    "\n",
    "        # Now, try to extract Title and Text from this block\n",
    "        # Assumption: Title is usually the first significant line(s) after the number.\n",
    "        #             Category might be present but harder to reliably extract.\n",
    "        #             The rest is the commentary body.\n",
    "\n",
    "        lines = [line.strip() for line in raw_block.strip().split('\\n') if line.strip()]\n",
    "\n",
    "        if not lines:\n",
    "            print(f\"Warning: No text content found for commentary {commentary_num}\")\n",
    "            continue\n",
    "\n",
    "        # Heuristic: Assume the first non-empty line is the Title\n",
    "        # This might need adjustment based on actual OCR output variations.\n",
    "        # Sometimes the title might be *before* the number on the page layout.\n",
    "        # Let's look *before* the number match as well.\n",
    "        # Find the text block between the *previous* match end and *this* match start\n",
    "        prev_end_index = matches[i-1].end() if i > 0 else 0\n",
    "        header_block = full_text[prev_end_index:match.start()]\n",
    "        header_lines = [line.strip() for line in header_block.strip().split('\\n') if line.strip()]\n",
    "\n",
    "        # Try to find title in header block first. Often Title\\nNumber or Category\\nTitle\\nNumber\n",
    "        title = \"Unknown Title\"\n",
    "        if len(header_lines) >= 1:\n",
    "             # If 2 lines before number, assume last is title, one before is category\n",
    "             if len(header_lines) >= 2:\n",
    "                 title = header_lines[-1] # Assume last line before number is title\n",
    "             else: # If only 1 line before number, assume it's the title\n",
    "                 title = header_lines[0]\n",
    "        elif lines: # If nothing before, check the first line *after* the number\n",
    "             title = lines[0]\n",
    "             # Remove title line from commentary text if found this way\n",
    "             commentary_text = \"\\n\".join(lines[1:]).strip()\n",
    "        else:\n",
    "            commentary_text = \"\\n\".join(lines).strip() # Use all lines if title wasn't separated\n",
    "\n",
    "        # If title was found *before* the number, the text starts *after* the number\n",
    "        if title in header_lines:\n",
    "             commentary_text = \"\\n\".join(lines).strip()\n",
    "\n",
    "\n",
    "        # Clean up potential OCR noise/artifacts if needed (optional)\n",
    "        commentary_text = re.sub(r'\\s*\\n\\s*', '\\n', commentary_text).strip() # Consolidate whitespace\n",
    "\n",
    "        # Calculate date\n",
    "        commentary_date = calculate_date_from_number(commentary_num)\n",
    "\n",
    "        commentary_data['Author'] = \"Phyllis Schlafly\"\n",
    "        commentary_data['title'] = title\n",
    "        commentary_data['date'] = commentary_date\n",
    "        commentary_data['commentary_number'] = commentary_num\n",
    "        commentary_data['text'] = commentary_text\n",
    "\n",
    "        # Basic validation\n",
    "        if title != \"Unknown Title\" and commentary_text:\n",
    "             commentaries.append(commentary_data)\n",
    "             print(f\"Successfully parsed commentary: {commentary_num} - {title[:30]}...\")\n",
    "        else:\n",
    "             print(f\"Warning: Could not fully parse commentary {commentary_num}. Title: '{title}', Text found: {bool(commentary_text)}\")\n",
    "\n",
    "\n",
    "    print(f\"Successfully parsed {len(commentaries)} commentaries.\")\n",
    "    return commentaries\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(PDF_FILE_PATH):\n",
    "        print(f\"Error: PDF file not found at '{PDF_FILE_PATH}'\")\n",
    "    else:\n",
    "        # 1. Extract text using OCR\n",
    "        pages_text = extract_text_from_pdf_ocr(PDF_FILE_PATH, POPPLER_PATH)\n",
    "\n",
    "        if pages_text:\n",
    "            # 2. Parse the extracted text\n",
    "            parsed_data = parse_commentaries(pages_text)\n",
    "\n",
    "            if parsed_data:\n",
    "                # 3. Write to JSON file\n",
    "                try:\n",
    "                    with open(OUTPUT_JSON_PATH, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(parsed_data, f, indent=4, ensure_ascii=False)\n",
    "                    print(f\"\\nSuccessfully wrote {len(parsed_data)} commentaries to '{OUTPUT_JSON_PATH}'\")\n",
    "                except IOError as e:\n",
    "                    print(f\"\\nError writing JSON file: {e}\")\n",
    "            else:\n",
    "                print(\"\\nNo commentaries could be successfully parsed from the PDF.\")\n",
    "        else:\n",
    "            print(\"\\nText extraction failed. Cannot proceed with parsing.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
